RNG_SEED: 0
NUM_GPUS: 1
NODES: 1
RANK: 0
WORLD_SIZE: 1
TRAIN:
  MAX_ITER: 30000
  LOG_STEP: 10
  SAVE_STEP: 1000
  EVAL_STEP: 1000
  RESUME: False
  USE_TENSORBOARD: True
OUTPUT:
  DIR: 'outputs/tsn_r50_ucf101_rgb_raw_dense_1x16x4'
DATASETS:
  MODALITY: 'RGB'
  TYPE: 'RawFrame'
  SAMPLE_STRATEGY: 'DenseSample'
  CLIP_LEN: 1
  FRAME_INTERVAL: 16
  NUM_CLIPS: 4
  NUM_SAMPLE_POSITIONS: 1
  TRAIN:
    NAME: 'UCF101'
    DATA_DIR: 'data/ucf101/rawframes'
    ANNOTATION_DIR: 'data/ucf101'
    SPLIT: 1
  TEST:
    NAME: 'UCF101'
    DATA_DIR: 'data/ucf101/rawframes'
    ANNOTATION_DIR: 'data/ucf101'
    SPLIT: 1
TRANSFORM:
  MEAN: (0.485, 0.456, 0.406)
  STD: (0.229, 0.224, 0.225)
  TRAIN:
    SCALE_JITTER: (256, 320)
    RANDOM_HORIZONTAL_FLIP: True
    COLOR_JITTER: (0.1, 0.1, 0.1, 0.1)
    RANDOM_ROTATION: 10
    RANDOM_CROP: True
    TRAIN_CROP_SIZE: 224
    RANDOM_ERASING: True
  TEST:
    SHORTER_SIDE: 256
    CENTER_CROP: True
    THREE_CROP: False
    TEST_CROP_SIZE: 256
DATALOADER:
  TRAIN_BATCH_SIZE: 24
  TEST_BATCH_SIZE: 4
  NUM_WORKERS: 8
MODEL:
  NAME: 'TSN'
  PRETRAINED: './outputs/tsn_r50_ucf101_rgb_raw_dense_1x16x4/model_030000.pth'
  SYNC_BN: True
  INPUT_SIZE: (224, 224, 3)
  BACKBONE:
    NAME: 'resnet50'
    PARTIAL_BN: False
    TORCHVISION_PRETRAINED: True
    ZERO_INIT_RESIDUAL: True
  HEAD:
    NAME: 'TSNHead'
    FEATURE_DIMS: 2048
    DROPOUT: 0.5
    NUM_CLASSES: 101
  RECOGNIZER:
    NAME: 'TSNRecognizer'
  CONSENSU:
    NAME: 'AvgConsensus'
  CRITERION:
    NAME: 'CrossEntropyLoss'
OPTIMIZER:
  NAME: 'sgd'
  LR: 1e-3
  WEIGHT_DECAY: 1e-4
  SGD:
    MOMENTUM: 0.9
LR_SCHEDULER:
  NAME: 'cosine_annearling_lr'
  IS_WARMUP: True
  COSINE_ANNEALING_LR:
    MINIMAL_LR: 3e-4
  WARMUP:
    ITERATION: 400
    MULTIPLIER: 1.0
VISUALIZATION:
  # Run model in DEMO mode.
  ENABLE: True
  # ---------------------------------------------------------------------------- #
  # Manager options
  # ---------------------------------------------------------------------------- #
  # Specify a camera device as input. This will be prioritized
  # over input manager if set.
  # If -1, use input manager instead.
  WEBCAM: -1
  # Path to input manager for demo.
  INPUT_VIDEO: './demo/videos/v_Rowing_g15_c04.avi'
  # Custom width for reading input manager data.
  DISPLAY_WIDTH: 0
  # Custom height for reading input manager data.
  DISPLAY_HEIGHT: 0
  # Frames per second rate for writing to output manager file.
  # If not set (-1), use fps rate from input file.
  OUTPUT_FPS: -1
  # If specified, the visualized outputs will be written this a manager file of
  # this path. Otherwise, the visualized outputs will be displayed in a window.
#  OUTPUT_FILE: './demo/results/v_Rowing_g15_c04_out.avi'
  # Number of overlapping frames between 2 consecutive clips.
  # Increase this number for more frequent action predictions.
  # The number of overlapping frames cannot be larger than
  # half of the sequence length `cfg.DATA.NUM_FRAMES * cfg.DATA.SAMPLING_RATE`
  BUFFER_SIZE: 30
  # Draw visualization frames in [keyframe_idx - CLIP_VIS_SIZE, keyframe_idx + CLIP_VIS_SIZE] inclusively.
  CLIP_VIS_SIZE: 10

  # Whether to run in with multi-threaded manager reader.
  THREAD_ENABLE: True
  # Take one clip for every `DEMO.NUM_CLIPS_SKIP` + 1 for prediction and visualization.
  # This is used for fast demo speed by reducing the prediction/visualiztion frequency.
  # If -1, take the most recent read clip for visualization. This mode is only supported
  # if `DEMO.THREAD_ENABLE` is set to True.
  NUM_CLIPS_SKIP: 0

  # ---------------------------------------------------------------------------- #
  # Visualizer options
  # ---------------------------------------------------------------------------- #
  # Number of processes to run manager visualizer.
  NUM_VIS_INSTANCES: 8
  # This is chosen based on distribution of examples in
  # each classes in AVA dataset.
  COMMON_CLASS_NAMES: [
      "watch (a person)",
      "talk to (e.g., self, a person, a group)",
      "listen to (a person)",
      "touch (an object)",
      "carry/hold (an object)",
      "walk",
      "sit",
      "lie/sleep",
      "bend/bow (at the waist)",
  ]
  # Path to a json file providing class_name - id mapping
  # in the format {"class_name1": id1, "class_name2": id2, ...}.
  LABEL_FILE_PATH: './data/ucf101/annotations/class2idx.json'
  # Colormap to for text boxes and bounding boxes colors
  COLORMAP: "Pastel2"
  # Threshold for common class names.
  COMMON_CLASS_THRES: 0.7
  # Theshold for uncommon class names. This will not be
  # used if `_C.VISUALIZATION.COMMON_CLASS_NAMES` is empty.
  UNCOMMON_CLASS_THRES: 0.8

  # ---------------------------------------------------------------------------- #
  # Predictor options
  # ---------------------------------------------------------------------------- #
  # Input format from demo manager reader ("RGB" or "BGR").
  INPUT_FORMAT: "BGR"
  # Visualize with top-k predictions or predictions above certain threshold(s).
  # Option: {"thres", "top-k"}
  VIS_MODE: "thres"
  # Slow-motion rate for the visualization. The visualized portions of the
  # manager will be played `_C.VISUALIZATION.SLOWMO` times slower than usual speed.
  SLOWMO: 1
